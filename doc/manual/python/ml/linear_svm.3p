.TH "Linear SVM" "" "" "" ""
.SH NAME
.PP
Linear SVM (Support Vector Machines) \- A classification algorithm to
predict the binary output with hinge loss.
.SH SYNOPSIS
.PP
class frovedis.mllib.svm.LinearSVC (penalty=\[aq]l2\[aq],
loss=\[aq]hinge\[aq], dual=True, tol=1e\-4,
.PD 0
.P
.PD
\  \ \  \  \  \ C=0.01, multi_class=\[aq]ovr\[aq], fit_intercept=True,
.PD 0
.P
.PD
\  \ \  \  \  \ intercept_scaling=1, class_weight=None, verbose=0,
.PD 0
.P
.PD
\  \ \  \  \  \ random_state=None, max_iter=1000, solver=\[aq]sag\[aq])
.SS Public Member Functions
.PP
fit(X, y, sample_weight=None)
.PD 0
.P
.PD
predict(X)
.PD 0
.P
.PD
predict_proba (X) save(filename)
.PD 0
.P
.PD
load(filename)
.PD 0
.P
.PD
debug_print()
.PD 0
.P
.PD
release()
.SH DESCRIPTION
.PP
Classification aims to divide items into categories.
The most common classification type is binary classification, where
there are two categories, usually named positive and negative.
Frovedis supports binary classification algorithms only.
.PP
The Linear SVM is a standard method for large\-scale classification
tasks.
It is a linear method with the loss function given by the \f[B]hinge
loss\f[]:
.IP
.nf
\f[C]
L(w;x,y)\ :=\ max{0,\ 1\-ywTx}
\f[]
.fi
.PP
Where the vectors x are the training data examples and y are their
corresponding labels (Frovedis considers negative response as \-1 and
positive response as 1, but when calling from scikit\-learn interface,
user should pass 0 for negative response and 1 for positive response
according to the scikit\-learn requirement) which we want to predict.
w is the linear model (also known as weight) which uses a single
weighted sum of features to make a prediction.
Linear SVM supports ZERO, L1 and L2 regularization to address the
overfit problem.
.PP
The gradient of the hinge loss is: \-y.x, if ywTx < 1, 0 otherwise.
.PD 0
.P
.PD
The gradient of the L1 regularizer is: sign(w)
.PD 0
.P
.PD
And The gradient of the L2 regularizer is: w
.PP
For binary classification problems, the algorithm outputs a binary svm
model.
Given a new data point, denoted by x, the model makes predictions based
on the value of wTx.
.PP
By default (threshold=0), if wTx >= 0, then the response is positive
(1), else the response is negative (0).
.PP
Frovedis provides implementation of linear SVM with two different
optimizers: (1) stochastic gradient descent with minibatch and (2) LBFGS
optimizer.
.PP
The simplest method to solve optimization problems of the form \f[B]min
f(w)\f[] is gradient descent.
Such first\-order optimization methods well\-suited for large\-scale and
distributed computation.
Whereas, L\-BFGS is an optimization algorithm in the family of
quasi\-Newton methods to solve the optimization problems of the similar
form.
.PP
Like the original BFGS, L\-BFGS (Limited Memory BFGS) uses an estimation
to the inverse Hessian matrix to steer its search through feature space,
but where BFGS stores a dense nxn approximation to the inverse Hessian
(n being the number of features in the problem), L\-BFGS stores only a
few vectors that represent the approximation implicitly.
L\-BFGS often achieves rapider convergence compared with other
first\-order optimization.
.PP
This module provides a client\-server implementation, where the client
application is a normal python scikit\-learn program.
Scikit\-learn has its own svm module providing the LinearSVC (Support
Vector Classification) support.
But that algorithm is non\-distributed in nature.
Hence it is slower when comparing with the equivalent Frovedis algorithm
(see frovedis manual for ml/linear_svm) with big dataset.
Thus in this implementation, a scikit\-learn client can interact with a
frovedis server sending the required python data for training at
frovedis side.
Python data is converted into frovedis compatible data internally and
the scikit\-learn ML call is linked with the respective frovedis ML call
to get the job done at frovedis server.
.PP
Scikit\-learn side call for Linear SVC quickly returns, right after
submitting the training request to the frovedis server with a unique
model ID for the submitted training request.
.PP
When operations like prediction will be required on the trained model,
scikit\-learn client sends the same request to frovedis server on the
same model (containing the unique ID) and the request is served at
frovedis server and output is sent back to the scikit\-learn client.
.SS Detailed Description
.SS LinearSVC()
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]penalty\f[]: A string object containing the regularizer type to
use.
(Default: \[aq]l2\[aq])
.PD 0
.P
.PD
\f[I]loss\f[]: A string object containing the loss function type to use.
(Default: \[aq]hinge\[aq])
.PD 0
.P
.PD
\f[I]dual\f[]: A boolean parameter (unused)
.PD 0
.P
.PD
\f[I]tol\f[]: A double parameter specifying the convergence tolerance
value, (Default: 1e\-4)
.PD 0
.P
.PD
\f[I]C\f[]: A double parameter containing the learning rate.
(Default: 0.01)
.PD 0
.P
.PD
\f[I]multi_class\f[]: A string object specifying type of classification.
(Default: \[aq]ovr\[aq])
.PD 0
.P
.PD
\f[I]fit_intercept\f[]: A boolean parameter specifying whether a
constant (intercept) should be added to the decision function.
(Default: True)
.PD 0
.P
.PD
\f[I]intercept_scaling\f[]: An integer parameter.
(unused)
.PD 0
.P
.PD
\f[I]class_weight\f[]: A python dictionary or a string object.
(unused)
.PD 0
.P
.PD
\f[I]verbose\f[]: An integer object specifying the log level to use.
(Default: 0)
.PD 0
.P
.PD
\f[I]random_state\f[]: An integer, None or RandomState instance.
(unused)
.PD 0
.P
.PD
\f[I]max_iter\f[]: An integer parameter specifying maximum iteration
count.
(Default: 1000)
.PD 0
.P
.PD
\f[I]solver\f[]: A string object specifying the solver to use.
(Default: \[aq]sag\[aq])
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It initialized a Lasso object with the given parameters.
.PP
The parameters: "dual", "intercept_scaling", "class_weight", and
"random_state" are not yet supported at frovedis side.
Thus they don\[aq]t have any significance in this call.
They are simply provided for the compatibility with scikit\-learn
application.
.PP
"penalty" can be either \[aq]l1\[aq] or \[aq]l2\[aq] (Default:
\[aq]l2\[aq]).
.PD 0
.P
.PD
"loss" value can only be \[aq]hinge\[aq].
.PP
"solver" can be either \[aq]sag\[aq] for frovedis side stochastic
gradient descent or \[aq]lbfgs\[aq] for frovedis side LBFGS optimizer
when optimizing the linear regression model.
.PP
"multi_class" can only be \[aq]ovr\[aq] as frovedis suppots binary
classification algorithms only at this moment.
.PP
"verbose" value is set at 0 by default.
But it can be set to 1 (for DEBUG mode) or 2 (for TRACE mode) for
getting training time logs from frovedis server.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS fit(X, y, sample_weight=None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]X\f[]: A scipy sparse matrix or any python array\-like object or an
instance of FrovedisCRSMatrix.
.PD 0
.P
.PD
\f[I]y\f[]: Any python array\-like object or an instance of
FrovedisDvector.
.PD 0
.P
.PD
\f[I]sample_weight\f[]: Python array\-like optional parameter.
(unused)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It accepts the training feature matrix (X) and corresponding output
labels (y) as inputs from the user and trains a linear regression model
with specifed regularization with those data at frovedis server.
.PP
It doesn\[aq]t support any initial weight to be passed as input at this
moment.
Thus the "sample_weight" parameter will simply be ignored.
It starts with an initial guess of zeros for the model vector and keeps
updating the model to minimize the cost function until convergence is
achieved or maximum iteration count is reached.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ sample\ CRS\ data\ file
mat\ =\ FrovedisCRSMatrix().load("./sample")
lbl\ =\ FrovedisDvector([1,0,1,1,1,0,1,1])

#\ fitting\ input\ matrix\ and\ label\ on\ linear\ SVC\ object
lr\ =\ LinearSVC(solver=\[aq]sgd\[aq],\ verbose=2).fit(mat,lbl)
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.PD 0
.P
.PD
Note that the call will return quickly, right after submitting the fit
request at frovedis server side with a unique model ID for the fit
request.
It may be possible that the training is not completed at the frovedis
server side even though the client scikit\-learn side fit() returns.
.SS predict(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]X\f[]: A scipy sparse matrix or any python array\-like object or an
instance of FrovedisCRSMatrix.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It accepts the test feature matrix (X) in order to make prediction on
the trained model at frovedis server.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a numpy array of double (float64) type containing the
predicted outputs.
.SS predict_proba(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]X\f[]: A scipy sparse matrix or any python array\-like object or an
instance of FrovedisCRSMatrix.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It accepts the test feature matrix (X) in order to make prediction on
the trained model at frovedis server.
But unlike predict(), it returns the probability values against each
input sample to be positive.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a numpy array of double (float64) type containing the
prediction probability values.
.SS save(filename)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]filename\f[]: A string object containing the name of the file on
which the target model is to be saved.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
On success, it writes the model information (weight values etc.) in the
specified file as little\-endian binary data.
Otherwise, it throws an exception.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS load(filename)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]filename\f[]: A string object containing the name of the file
having model information to be loaded.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It loads the model from the specified file (having little\-endian binary
data).
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" instance.
.SS debug_print()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It shows the target model information (weight values etc.) on the server
side user terminal.
It is mainly used for debugging purpose.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS release()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It can be used to release the in\-memory model at frovedis server.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SH SEE ALSO
.PP
logistic_regression, dvector, crs_matrix
